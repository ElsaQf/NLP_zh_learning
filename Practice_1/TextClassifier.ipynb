{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:20:29.135379Z",
     "start_time": "2019-10-07T07:20:29.115856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集：科技、汽车、娱乐、军事、体育 5类\n",
    "### 格式：\\[[word1 word2 ... word] category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:20:30.573502Z",
     "start_time": "2019-10-07T07:20:30.225217Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:20:33.374127Z",
     "start_time": "2019-10-07T07:20:32.514952Z"
    }
   },
   "outputs": [],
   "source": [
    "df_technology = pd.read_csv('./data/technology_news.csv', encoding='utf-8')\n",
    "df_technology = df_technology.dropna()\n",
    "\n",
    "df_car = pd.read_csv('./data/car_news.csv', encoding='utf-8')\n",
    "df_car = df_car.dropna()\n",
    "\n",
    "df_entertainment = pd.read_csv('./data/entertainment_news.csv', encoding='utf-8')\n",
    "df_entertainment = df_entertainment.dropna()\n",
    "\n",
    "df_military = pd.read_csv('./data/military_news.csv', encoding='utf-8')\n",
    "df_military = df_military.dropna()\n",
    "\n",
    "df_sports = pd.read_csv('./data/sports_news.csv', encoding='utf-8')\n",
    "df_sports = df_sports.dropna()\n",
    "\n",
    "technology = df_technology.content.values.tolist()[1000:21000]\n",
    "car = df_car.content.values.tolist()[1000:21000]\n",
    "entertainment = df_entertainment.content.values.tolist()[:20000]\n",
    "military = df_military.content.values.tolist()[:20000]\n",
    "sports = df_sports.content.values.tolist()[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:21:50.923723Z",
     "start_time": "2019-10-07T07:21:50.911567Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords = pd.read_csv('./data/stopwords.txt', index_col=False, quoting=3, sep=\"\\t\", names=['stopword'], encoding='utf-8')\n",
    "stopwords = stopwords['stopword'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:21:53.751882Z",
     "start_time": "2019-10-07T07:21:53.745450Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_text(content_lines, sentences, category):\n",
    "    for line in content_lines:\n",
    "        try:\n",
    "            segs = jieba.lcut(line)\n",
    "            segs = filter(lambda x: len(x)>1, segs)\n",
    "            segs = filter(lambda x: x not in stopwords, segs)\n",
    "            sentences.append((\" \".join(list(segs)), category))\n",
    "        except:\n",
    "            print(line)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:24:02.102613Z",
     "start_time": "2019-10-07T07:21:56.206482Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.490 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "process_text(technology, sentences, 'technology')\n",
    "process_text(car, sentences, 'car')\n",
    "process_text(entertainment, sentences, 'entertainment')\n",
    "process_text(military, sentences, 'military')\n",
    "process_text(sports, sentences, 'sports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:29:37.433342Z",
     "start_time": "2019-10-07T07:29:37.429089Z"
    }
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:29:39.382106Z",
     "start_time": "2019-10-07T07:29:39.308799Z"
    }
   },
   "outputs": [],
   "source": [
    "random.shuffle(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:29:41.650520Z",
     "start_time": "2019-10-07T07:29:41.644324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "规划 预计 2020 中国 汽车 年产量 3000 万辆 2025 3500 万辆 car\n",
      "山东 菏泽 武县 伯乐 大街 显眼 手机 通讯 招牌 春节 张灯结彩 景象 交相 呼应 热情 导购员 介绍 OPPO 最新 机型 拥有 800 人口 乡镇 市场 计入 合作 网点 运营商 门店 OPPO 自营 体验 technology\n",
      "提前 判断 航母 下水 标志 悬挂 满旗 大型 船舶 下水 时要 隆重 仪式 悬挂 满旗 满灯 军舰 特有 庆典 方式 庞大 舰艇 悬挂 满旗 提前 判别 航母 下水 最为 简单 直观 判断 military\n",
      "投资 重头戏 融创 150 亿元 投资 分为 乐视 优质 业务 板块 第一 围绕 乐视 体系 上市公司 视网 展开 融创 收购 乐视 掌门人 贾跃亭 持有 8.61% 股权 围绕 以乐视 超级 电视 板块 乐视致 展开 融创 79.5 亿元 价格 增发 33.5% 股权 49.5 亿元 从乐 视网 和鑫乐 资产 手中 购买 共计 26.1% 增发 老股 增资 亿元 增发 10% 第三 围绕 乐视 影业 展开 整体 估值 亿元 融创 10.5 亿元 收购 乐视 控股 持有 15% 股份 technology\n",
      "聚众 互动 制定 战队 赛制 强化 队长 战队 作用 意义 团队 记分牌 增加 全新 用途 每支 队伍 局势 实时 变化 选择 战术 达成 团队 目标 著名 导演 王岳伦 比赛 战队 队长 评论 团队 赛制 队员 感受 以往 德州 扑克 比赛 体会 不到 团队 凝聚力 这是 赛制 赛后 世界 著名 职业 扑克 选手 David Chiu 提到 比赛 赛制 展现出 团队 价值 团队 赛制 非常适合 中国 德州 扑克 中国 推广 起到 作用 sports\n",
      "黄蓉 郭靖 扮演者 观众 心中 经典 形象 合二为一 见仁见智 范畴 entertainment\n",
      "比巴方 方队 巴方 方队 地上 一道 一道 行进 方向线 实际上 方队 设计 方队 实际上 可行 把握 行进 方向 military\n",
      "去年 夏窗 曼城 曼联 切尔西 阿森纳 引援 投入 跻身 欧洲 前十名 曼彻斯特 双雄 包揽 两位 曼城 耗资 2.13 欧元 唯一 投入 超过 欧元 俱乐部 投入 1.91 欧元 引进 斯通斯 萨内 赫苏斯 京多安 诺利托 布拉沃 大牌 新援 新援 表现 民调 排名 萨内 京多安 诺利托 斯通斯 布拉沃 倒数 第一 球队 短板 曼城 引援 花钱 现仅排 积分榜 落后 榜首 分之多 争冠 很难 sports\n",
      "国家 漏洞 平台 聚集 庞大 帽子 团队 补天 平台 注册 帽子 超过 万名 美国 漏洞 平台 近万名 帽子 发放 漏洞 奖金 各国 漏洞 平台 合作 协同 西方 黑客 技术 优势 提升 网站 防护 能力 有利于 技术 共享 人才 共享 漏洞 响应 全球 互联网安全 水平 能力 提升 technology\n",
      "马术 中国 关注度 提升 青少年 马术 活动 发展 赛事 主办方 大陆 赛马 去年 首次 推出 青马 乐园 趣味 推广 2017 运营 中国 首个 青少年 马术 平台 sports\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences[:10]:\n",
    "    print(sentence[0], sentence[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:30:08.543318Z",
     "start_time": "2019-10-07T07:30:08.536831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('规划 预计 2020 中国 汽车 年产量 3000 万辆 2025 3500 万辆', 'car')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:30:22.219348Z",
     "start_time": "2019-10-07T07:30:21.852367Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:30:24.235516Z",
     "start_time": "2019-10-07T07:30:24.110339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65696"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = zip(*sentences)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1234)\n",
    "\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:30:37.321299Z",
     "start_time": "2019-10-07T07:30:37.301410Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:30:42.521418Z",
     "start_time": "2019-10-07T07:30:41.141618Z"
    }
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(analyzer='word',\n",
    "                     max_features=4000,)\n",
    "vec.fit(x_train)\n",
    "\n",
    "def get_features(x):\n",
    "    vec.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:30:48.509104Z",
     "start_time": "2019-10-07T07:30:48.505555Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:30:53.438776Z",
     "start_time": "2019-10-07T07:30:52.280454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifer = MultinomialNB()\n",
    "classifer.fit(vec.transform(x_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:31:00.606768Z",
     "start_time": "2019-10-07T07:31:00.236730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8378921411936618"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifer.score(vec.transform(x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:31:03.995697Z",
     "start_time": "2019-10-07T07:31:03.989274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21899"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:38:53.504449Z",
     "start_time": "2019-10-07T07:38:28.765073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8802685054112059"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vec = CountVectorizer(analyzer='word',\n",
    "                     ngram_range=(1,4),\n",
    "                     max_features=20000,)\n",
    "vec.fit(x_train)\n",
    "\n",
    "def get_features(x):\n",
    "    vec.transform(x)\n",
    "    \n",
    "classifer = MultinomialNB()\n",
    "classifer.fit(vec.transform(x_train), y_train)\n",
    "\n",
    "classifer.score(vec.transform(x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:41:04.661578Z",
     "start_time": "2019-10-07T07:41:04.657187Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:47:50.628740Z",
     "start_time": "2019-10-07T07:47:45.142750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8810618069116188\n"
     ]
    }
   ],
   "source": [
    "def stratifiedkfold_cv(x, y, clf_class, shuffle=True, n_folds=5, **kwargs):\n",
    "    stratifiedk_fold = StratifiedKFold(y, n_folds=n_folds, shuffle=shuffle)\n",
    "    y_pred = y[:]\n",
    "    for train_index, test_index in stratifiedk_fold:\n",
    "        X_train, X_test = x[train_index], x[test_index]\n",
    "        y_train = y[train_index]\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred[test_index] = clf.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "NB = MultinomialNB\n",
    "print(precision_score(y, stratifiedkfold_cv(vec.transform(x), np.array(y), NB), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T08:02:32.309837Z",
     "start_time": "2019-10-07T08:01:43.891227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['military']\n",
      "0.8802685054112059\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "class TextClassifier():\n",
    "\n",
    "    def __init__(self, classifier=MultinomialNB()):\n",
    "        self.classifier = classifier\n",
    "        self.vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,4), max_features=20000)\n",
    "\n",
    "    def features(self, X):\n",
    "        return self.vectorizer.transform(X)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.vectorizer.fit(X)\n",
    "        self.classifier.fit(self.features(X), y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.classifier.predict(self.features([x]))\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.classifier.score(self.features(X), y)\n",
    "    \n",
    "text_classifier = TextClassifier()\n",
    "text_classifier.fit(x_train, y_train)\n",
    "print(text_classifier.predict('这 是 有史以来 最 大 的 一 次 军舰 演习'))\n",
    "print(text_classifier.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T08:29:57.474151Z",
     "start_time": "2019-10-07T08:22:06.543520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['military']\n",
      "0.8762043928946527\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "class TextClassifier():\n",
    "    def __init__(self, classifier=SVC(kernel='linear')):\n",
    "        self.classifier = classifier\n",
    "        self.vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                                        ngram_range=(1,4),\n",
    "                                        max_features=12000)\n",
    "        \n",
    "    def features(self, X):\n",
    "        return self.vectorizer.transform(X)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.vectorizer.fit(X)\n",
    "        self.classifier.fit(self.features(X), y)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.classifier.predict(self.features([x]))\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return self.classifier.score(self.features(X), y)\n",
    "    \n",
    "text_classifier = TextClassifier()\n",
    "text_classifier.fit(x_train, y_train)\n",
    "print(text_classifier.predict('这 是 有史以来 最 大 的 一 次 军舰 演习'))\n",
    "print(text_classifier.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
